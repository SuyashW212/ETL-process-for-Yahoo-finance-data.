{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Attempt 1: Using Beautiful soup and selenium."
      ],
      "metadata": {
        "id": "QZFxM9nVMvfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In first attempt I tried to scrap data using beautiful soup and selenium, steps given as below:\n"
      ],
      "metadata": {
        "id": "MJ8FsqoPNN4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "class Market:\n",
        "    def __init__(self, url):\n",
        "        self.Datadict = {}\n",
        "        self.url = url\n",
        "        self.date=[]\n",
        "        self.tinkerl = []\n",
        "        self.pricel = []\n",
        "        self.pricechangel = []\n",
        "        self.changeperl = []\n",
        "        self.marketCapl = []\n",
        "        self.volumel = []\n",
        "        self.driver = self.web_driver()\n",
        "        self.ExNoRows(self.url)\n",
        "#Selenium intialization---------------------------------------------\n",
        "    def web_driver(self):\n",
        "        options = webdriver.ChromeOptions()\n",
        "        options.add_argument(\"--verbose\")\n",
        "        options.add_argument('--no-sandbox')\n",
        "        options.add_argument('--headless')\n",
        "        options.add_argument('--disable-gpu')\n",
        "        options.add_argument(\"--window-size=1920, 1200\")\n",
        "        options.add_argument('--disable-dev-shm-usage')\n",
        "        driver = webdriver.Chrome(options=options)\n",
        "        return driver\n",
        "#No. of data------------------------------------------------------\n",
        "    def ExNoRows(self, url):\n",
        "        self.driver.get(url)\n",
        "        time.sleep(3)\n",
        "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "        totalrow = soup.find('div', {'class': 'total yf-1tdhqb1'})\n",
        "        if totalrow:\n",
        "            row = totalrow.text.split(\" \")\n",
        "            Total = int(row[2])\n",
        "            print(\"Total rows:\", Total)\n",
        "            i = 0\n",
        "            count = 100\n",
        "            while i < 100:\n",
        "                upd_url = f'{self.url}?start={i}&count={count}'\n",
        "                print(f\"{upd_url}\")\n",
        "                self.extract_data(upd_url)\n",
        "                i =i+ count\n",
        "#Calling Transformation-------------------------------------\n",
        "            self.dataframe_form()\n",
        "            self.data['MarketCapital_inB']=self.data['MarketCapital_inB'].apply(self.transform_MarketCap)\n",
        "            self.data['Volume_inM']=self.data['Volume_inM'].apply(self.transform_Volume)\n",
        "        else:\n",
        "            print(\"Total row not found\")\n",
        "#Extraction-------------------------------------------------\n",
        "    def extract_data(self, url):\n",
        "        self.driver.get(url)\n",
        "        time.sleep(3)\n",
        "\n",
        "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "        tbody = soup.find('tbody')\n",
        "\n",
        "        if tbody:\n",
        "            tr = tbody.find_all('tr')\n",
        "            for i in range(len(tr)):\n",
        "                try:\n",
        "                    tinker = tr[i].find('span', {'class': 'symbol yf-1m808gl'}).text\n",
        "                    price = tr[i].find_all('fin-streamer', {'data-field': 'regularMarketPrice'})[0].text\n",
        "                    pricechange = tr[i].find_all('fin-streamer', {'data-field': 'regularMarketChange'})[0].text\n",
        "                    chngper = tr[i].find_all('fin-streamer', {'data-field': 'regularMarketChangePercent'})[1].text\n",
        "                    marketCap = tr[i].find_all('fin-streamer', {'data-field': 'marketCap'})[0].text\n",
        "                    volume = tr[i].find_all('fin-streamer', {'data-field': 'regularMarketVolume'})[0].text\n",
        "                    today=date.today()\n",
        "                    self.date.append(today)\n",
        "                    self.tinkerl.append(tinker)\n",
        "                    self.pricel.append(price)\n",
        "                    self.pricechangel.append(pricechange)\n",
        "                    self.changeperl.append(chngper)\n",
        "                    self.marketCapl.append(marketCap)\n",
        "                    self.volumel.append(volume)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing row {i}\")\n",
        "                    continue\n",
        "\n",
        "        else:\n",
        "            print(\"No data exist in tbody.\")\n",
        "\n",
        "#Transformation--------------------------------------\n",
        "\n",
        "    def dataframe_form(self):\n",
        "\n",
        "        self.Datadict = {\n",
        "            'Date':self.date,\n",
        "            'Symbol': self.tinkerl,\n",
        "            'MarketPrice': self.pricel,\n",
        "            'PriceChange': self.pricechangel,\n",
        "            'ChangePercent': self.changeperl,\n",
        "            'MarketCapital_inB': self.marketCapl,\n",
        "            'Volume_inM': self.volumel\n",
        "        }\n",
        "\n",
        "        self.data = pd.DataFrame(self.Datadict)\n",
        "        print(self.data.head())\n",
        "\n",
        "    def transform_MarketCap(self,MarketCap):\n",
        "      if 'T' in MarketCap:\n",
        "        return round(float(MarketCap.replace('T',''))*1000,2)\n",
        "      if 'B' in MarketCap:\n",
        "        return round(float(MarketCap.replace('B','')),2)\n",
        "\n",
        "    def transform_Volume(self,Volume):\n",
        "      return round(float(Volume.replace('M','')),2)\n",
        "\n",
        "\n",
        "\n",
        "    def return_dataframe(self):\n",
        "        return self.data\n",
        "\n",
        "\n",
        "\n",
        "market = Market('https://finance.yahoo.com/markets/stocks/most-active/')\n",
        "df = market.return_dataframe()\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "f-dMnnQfK63j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempt 2:Automation using JSON request:"
      ],
      "metadata": {
        "id": "e3B8es3QHhd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "!pip install \"pymongo[srv]\"\n",
        "import pymongo\n",
        "\n",
        "\n",
        "class Market:\n",
        "    def __init__(self):\n",
        "        check_1=self.server_intialization()\n",
        "        print(check_1)\n",
        "        check_2=self.Ext_Data()\n",
        "        print(check_2)\n",
        "\n",
        "    def server_intialization(self):\n",
        "      try:\n",
        "        client = pymongo.MongoClient(\"mongodb+srv://20036167:qy48xX5YreOhyB2S@mydata.jus5a.mongodb.net/?retryWrites=true&w=majority&appName=MyData\")\n",
        "        try:\n",
        "          db=client['Stock_Data']\n",
        "          self.collection=db['Most_Active']\n",
        "          return(\"Database connected successfully\")\n",
        "        except:\n",
        "          return(\"Database or collection intialization error.\")\n",
        "      except:\n",
        "        return(\"Database connection error.\")\n",
        "\n",
        "\n",
        "#No. of data------------------------------------------------------\n",
        "    def Ext_Data(self):\n",
        "      start=0\n",
        "      i=0\n",
        "      while True:\n",
        "        url=f\"https://query1.finance.yahoo.com/v1/finance/screener/predefined/saved?count=100&formatted=true&scrIds=MOST_ACTIVES&sortField=&sortType=&start={start}&fields=ticker%2Csymbol%2ClongName%2Csparkline%2CshortName%2CregularMarketPrice%2CregularMarketChange%2CregularMarketChangePercent%2CregularMarketVolume%2CaverageDailyVolume3Month%2CmarketCap%2CtrailingPE%2CfiftyTwoWeekChangePercent%2CfiftyTwoWeekRange%2CregularMarketOpen&lang=en-US&region=US\"\n",
        "        data='count=100&formatted=true&scrIds=MOST_ACTIVES&sortField=&sortType=&start=100&fields=ticker%2Csymbol%2ClongName%2Csparkline%2CshortName%2CregularMarketPrice%2CregularMarketChange%2CregularMarketChangePercent%2CregularMarketVolume%2CaverageDailyVolume3Month%2CmarketCap%2CtrailingPE%2CfiftyTwoWeekChangePercent%2CfiftyTwoWeekRange%2CregularMarketOpen&lang=en-US&region=US'\n",
        "        headers={'accept': '*/*',\n",
        "'accept-encoding': 'gzip, deflate, br, zstd',\n",
        "'accept-language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',\n",
        "'cookie': 'GUC=AQABCAFnLh1nXkIhqgSw&s=AQAAALwyMQnh&g=ZyzSJw; A1=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; A3=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; tbla_id=04e8b518-5f25-44a0-8850-e7d6c6ef1076-tuctdf41a4a; PRF=t%3DMCHP; A1S=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; cmp=t=1732102191&j=1&u=1---&v=53; EuConsent=CQHuB4AQHuB4AAOACBENBQFoAP_gAEPgACiQKZNB9G7WTXFneXp2YPskOYUX0VBJ4MAwBgCBAcABzBIUIBwGVmAzJEyIICACGAIAIGBBIABtGAhAQEAAYIAFAABIAEgAIBAAIGAAACAAAABACAAAAAAAAAAQgEAXMBQgmAZEBFoIQUhAggAgAQAAAAAEAIgBCgQAEAAAQAAICAAIACgAAgAAAAAAAAAEAFAIEQAAAAECAotkfQAAAAAAAAAAAAAAAAABBTIAEg1KiAIsCQkIBAwggQAiCgIAKBAAAAAQIAAACYIChAGASowEQAgBAAAAAAAAAAQAIAAAIAEIAAgACBAAAAABAAEABAIAAAQAAAAAAAAAAAAAAAAAAAAAAAAAxACEEAAIAIIACCgAAAAEAAAAAAAAABEAAQAAAAAAAAAAAAABEAAAAAAAAAAAAAAAAAABAAAAAAAAAEAIgsAAAAAAAAAAAAAAAAAAIAA; axids=gam=y-D6u6S6xE2uK_Pd67HRy4OefGieRfEKiB~A&dv360=eS11cGZON0pKRTJ1RkwyRzhvLkFseTkzWDRVSFBsUTNtaX5B&ydsp=y-8BmzyhtE2uKeLoVJQo5VsAZuEn0lxCWq~A&tbla=y-br54pG1E2uKNCK2YMneD1EuBaVtqWq8h~A',\n",
        "'origin': 'https://finance.yahoo.com',\n",
        "'priority': 'u=1, i',\n",
        "'referer': 'https://finance.yahoo.com/markets/stocks/most-active/?start=0&count=100',\n",
        "'sec-ch-ua': '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
        "'sec-ch-ua-mobile': '?0',\n",
        "'sec-ch-ua-platform': '\"Windows\"',\n",
        "'sec-fetch-dest': 'empty',\n",
        "'sec-fetch-mode': 'cors',\n",
        "'sec-fetch-site': 'same-site',\n",
        "'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
        "'version': '0'}\n",
        "        r= requests.get(url,headers=headers,data=data)\n",
        "        j=json.loads(r.content)\n",
        "        self.data=pd.json_normalize(j['finance']['result'][0]['quotes'])\n",
        "        if int(self.data.shape[0])!=0:\n",
        "          self.dataframe_form()\n",
        "          self.transform_MarketCap()\n",
        "          self.transform_Volume()\n",
        "          self.data['Market_category']=self.data['marketCap.raw'].apply(self.market_category)\n",
        "          self.data['Current_position']=(self.data['regularMarketPrice.raw']-self.data['regularMarketOpen.raw']).apply(self.market_trend)\n",
        "          self.normalize_pp()\n",
        "          self.round_data()\n",
        "          self.load_data()\n",
        "          start+=100\n",
        "          i=int(self.data.shape[0])\n",
        "          print(f\"{i} is being processed\")\n",
        "          if i <100:\n",
        "            return(\"ETL process successfully completed.\")\n",
        "            break;\n",
        "\n",
        "        else:\n",
        "          return(\"No data found or Extraction is incomplete.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Transformation--------------------------------------\n",
        "\n",
        "    def dataframe_form(self):\n",
        "\n",
        "        self.data = pd.DataFrame(self.data)\n",
        "\n",
        "\n",
        "    def transform_MarketCap(self): # in billion\n",
        "      self.data['marketCap.raw']=round(self.data['marketCap.raw']/1000000000,2)\n",
        "\n",
        "\n",
        "    def transform_Volume(self): #in million\n",
        "      self.data['regularMarketVolume.raw']=round(self.data['regularMarketVolume.raw']/1000000,2)\n",
        "\n",
        "    def market_category(self,value):\n",
        "      if value<=2.0:\n",
        "        return \"Small cap\"\n",
        "      elif value>2.0 and value <=10.0:\n",
        "        return \"Medium cap\"\n",
        "      elif value >10.0 and value <=200.0:\n",
        "        return \"Large Cap\"\n",
        "      else:\n",
        "        return \"Mega Cap\"\n",
        "\n",
        "    def market_trend(self,value):\n",
        "      if value<0:\n",
        "        return \"Negative\"\n",
        "      elif value>0:\n",
        "        return \"Positive\"\n",
        "      else:\n",
        "        return \"Side-ways\"\n",
        "\n",
        "    def normalize_pp(self):\n",
        "      self.data[\"Normalize_price_posn\"]=round((self.data[\"regularMarketPrice.raw\"]-self.data[\"fiftyTwoWeekLow.raw\"])/(self.data[\"fiftyTwoWeekHigh.raw\"]-self.data[\"fiftyTwoWeekLow.raw\"]),2)\n",
        "\n",
        "    def round_data(self):\n",
        "      self.data[\"regularMarketChange.raw\"]=round(self.data[\"regularMarketChange.raw\"],2)\n",
        "      self.data[\"regularMarketChangePercent.raw\"]=round(self.data[\"regularMarketChangePercent.raw\"],2)\n",
        "\n",
        "\n",
        "#Data loading--------------------------------------\n",
        "    def load_data(self):\n",
        "      data_main= self.data[['symbol','shortName','Market_category','Current_position','Normalize_price_posn','regularMarketPreviousClose.raw','regularMarketOpen.raw','regularMarketPrice.raw','marketCap.raw','regularMarketVolume.raw','regularMarketChange.raw','regularMarketChangePercent.raw','regularMarketDayLow.raw','regularMarketDayHigh.raw','fiftyTwoWeekLow.raw','fiftyTwoWeekHigh.raw']]\n",
        "      Most_Active=data_main.to_dict(orient='records')\n",
        "      self.collection.insert_many(Most_Active)\n",
        "\n",
        "\n",
        "market = Market()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvT1TkCzo0NA",
        "outputId": "a3880fb4-0416-4bcd-e4ae-7f777038e34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "\u001b[33mWARNING: pymongo 4.10.1 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo[srv]) (2.7.0)\n",
            "Database connected successfully\n",
            "100 is being processed\n",
            "100 is being processed\n",
            "51 is being processed\n",
            "ETL process successfully completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing part:"
      ],
      "metadata": {
        "id": "JlQnEUXHK4_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class test:\n",
        "  def __init__(self):\n",
        "    self.collection=None\n",
        "    self.test_data()\n",
        "\n",
        "  def mongo_connection(self):\n",
        "    try:\n",
        "      client = pymongo.MongoClient(\"mongodb+srv://20036167:qy48xX5YreOhyB2S@mydata.jus5a.mongodb.net/?retryWrites=true&w=majority&appName=MyData\")\n",
        "      try:\n",
        "        db=client['Stock_Data']\n",
        "        self.collection=db['Most_Active']\n",
        "        return(\"Database connected successfully\")\n",
        "      except:\n",
        "        return(\"Database or collection error.\")\n",
        "    except:\n",
        "      return(\"Database connection error.\")\n",
        "\n",
        "  def fetched_data(self):\n",
        "    try:\n",
        "      self.data=self.collection.find()\n",
        "      df=pd.DataFrame(self.data)\n",
        "      query={'symbol':'NVDA'}\n",
        "      data_check=list(self.collection.find(query))\n",
        "      print(data_check)\n",
        "      return(f\"Data Fetched successfully, Number of records {len(df)}\")\n",
        "    except:\n",
        "      return(\"Data not present.\")\n",
        "\n",
        "\n",
        "  def test_data(self):\n",
        "    print(self.mongo_connection())\n",
        "    print(self.fetched_data())\n",
        "\n",
        "Test=test()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ6ZjhgeK31Q",
        "outputId": "19cb42e0-5f6f-491f-a712-6fc42cf12b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database connected successfully\n",
            "[{'_id': ObjectId('675af5ee9af996426fb41aeb'), 'symbol': 'NVDA', 'shortName': 'NVIDIA Corporation', 'Market_category': 'Mega Cap', 'Current_position': 'Positive', 'Normalize_price_posn': 0.85, 'regularMarketPreviousClose.raw': 139.31, 'regularMarketOpen.raw': 137.1, 'regularMarketPrice.raw': 137.216, 'marketCap.raw': 3360.42, 'regularMarketVolume.raw': 23.26, 'regularMarketChange.raw': -2.09, 'regularMarketChangePercent.raw': -1.5, 'regularMarketDayLow.raw': 135.88, 'regularMarketDayHigh.raw': 137.35, 'fiftyTwoWeekLow.raw': 47.32, 'fiftyTwoWeekHigh.raw': 152.89}]\n",
            "Data Fetched successfully, Number of records 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "In this modern IT-centric world where major organizational decision-making is dependent on data, ETL is the backbone of data preparation. **ETL** stands for **Extract**, **Transform** and **Load**. The extract step includes data acquisition using  APIs, web scrapping, DB extracts, etc., Transform ensures the input and structured output where it is transformed into a form compatible with the different reporting requirements. It thus allows the integration of data from various sources into the organization, transforming it concerning reporting standards, and eventually making it viewable and understandable."
      ],
      "metadata": {
        "id": "DcmEeoZlRRAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Purpose of this Project\n",
        "The prime objective of this project is to automate the ETL process for stock market data, specifically from the most active stocks. The project ensures that stock data is brought in from Yahoo Finance, transformed for analysis, and loaded into a database for convenient access, storage and reporting. This python script for most active stocks provides data for processing financial analysis and decision-making support by being reliable and scalable."
      ],
      "metadata": {
        "id": "j01ixPZ1WrpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "This project follows **ETL** process to automate the flow of data from Yahoo finance to MongoDB database and it can be given as follows:\n",
        "\n",
        "1. **Extraction**:\n",
        "The data extaction from Yahoo finance is done using a public **API (Application Programming Interface)**. The python script sends GET request to a given URL and retives the data in JSON format.\n",
        "\n",
        "2. **Transformation**:\n",
        "Transformations ensures that raw data is refined into a format that is accurate, consistent, and ready for analysis of storage. Raw data can be misleading, difficult to interpret or inefficient for further processing. Hence it is a necessary step to apply transformation.\n",
        "Several data transformation steps are applied to the raw data:\n",
        "\n",
        "*   Market Capitalization Transformation: Converts market cap values from raw numbers to billions for easier interpretation.\n",
        "*   Volume Transformation: Converts volume data from raw numbers to millions.\n",
        "\n",
        "*   Price Normalization: Normalizes the stock price based on its 52-week low and high.\n",
        "*   Market Trend Calculation: Identifies whether the stockâ€™s price is moving in a positive, negative, or side-ways direction.\n",
        "\n",
        "\n",
        "*   Stock Classification: Stocks are categorized as small-cap, medium-cap, large-cap, or mega-cap based on their market cap value.\n",
        "\n",
        "3. **Load**:\n",
        "After transforming the data, the final processed DataFrame is loaded into MongoDB using the pymongo library.The MongoDB collection stores the data in a structured format, making it easy to query and generate reports.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ccqpUe1wfEK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code implementation\n",
        "**Step 1: Library intialization:**\n",
        "Intialized all the required libraries for this task.\n",
        "\n",
        "```\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "!pip install \"pymongo[srv]\"\n",
        "import pymongo\n",
        "```\n",
        "1. requests library: It is used for making HTTPS requests to public APIs. In this script, \"requests\" is used to send a GET request to the Yahoo Fiance API for most active stocks.\n",
        "2. JSON library: It is use to parse and manipulate JSON data. The data extracted from the site is in \"JSON\" format, using this library we can load and convert data in python dictionary.\n",
        "3. Pandas library: It is used for Data manipulation and analysis in Dataframe format. Here, use case of this library is for normalization and transformation of data.\n",
        "4. pymongo library: A python driver for interacting with mongoDB.\n",
        "\n",
        "**Step 2: class Intialization :**\n",
        "\n",
        "Initialization of class which will execute whole process\n",
        "```\n",
        "market = Market()\n",
        "```\n",
        "\n",
        "\n",
        "**Step 3: Constructor initialization:**\n",
        "\n",
        "\n",
        "```\n",
        " def __init__(self):\n",
        "        self.server_intialization()\n",
        "        self.Ext_Data()\n",
        "```\n",
        "This method will lead to database connection and extraction of data.\n",
        "\n",
        "\n",
        "```\n",
        "def server_intialization(self):\n",
        "      try:\n",
        "        client = pymongo.MongoClient(\"mongodb+srv://20036167:qy48xX5YreOhyB2S@mydata.jus5a.mongodb.net/?retryWrites=true&w=majority&appName=MyData\",ssl=True)\n",
        "        try:\n",
        "          db=client['Stock_Data']\n",
        "          self.collection=db['Most_Active']\n",
        "          return(\"Database connected successfully\")\n",
        "        except:\n",
        "          return(\"Database or collection intialization error.\")\n",
        "      except:\n",
        "        return(\"Database connection error.\")\n",
        "```\n",
        "Here, Database is getting connected before loading data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Step 4: Data Extraction:**\n",
        "\n",
        "In data extraction stage, loop the row count till it becomes less than the maximum row count allowed by the site (100 in this case). Within that, making HTTPS requests to Yahoo Finance's most active stock site. \"**json.load()**\"  function is loading the json format data into python dictonary. Further, applying transformation and feature engineering for the extraction of meaningful insights.\n",
        "\n",
        "```\n",
        "def Ext_Data(self):\n",
        "      start=0\n",
        "      i=0\n",
        "      while True:\n",
        "        url=f\"https://query1.finance.yahoo.com/v1/finance/screener/predefined/saved?count=100&formatted=true&scrIds=MOST_ACTIVES&sortField=&sortType=&start={start}&fields=ticker%2Csymbol%2ClongName%2Csparkline%2CshortName%2CregularMarketPrice%2CregularMarketChange%2CregularMarketChangePercent%2CregularMarketVolume%2CaverageDailyVolume3Month%2CmarketCap%2CtrailingPE%2CfiftyTwoWeekChangePercent%2CfiftyTwoWeekRange%2CregularMarketOpen&lang=en-US&region=US\"\n",
        "        data='count=100&formatted=true&scrIds=MOST_ACTIVES&sortField=&sortType=&start=100&fields=ticker%2Csymbol%2ClongName%2Csparkline%2CshortName%2CregularMarketPrice%2CregularMarketChange%2CregularMarketChangePercent%2CregularMarketVolume%2CaverageDailyVolume3Month%2CmarketCap%2CtrailingPE%2CfiftyTwoWeekChangePercent%2CfiftyTwoWeekRange%2CregularMarketOpen&lang=en-US&region=US'\n",
        "        headers={'accept': '*/*',\n",
        "'accept-encoding': 'gzip, deflate, br, zstd',\n",
        "'accept-language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',\n",
        "'cookie': 'GUC=AQABCAFnLh1nXkIhqgSw&s=AQAAALwyMQnh&g=ZyzSJw; A1=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; A3=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; tbla_id=04e8b518-5f25-44a0-8850-e7d6c6ef1076-tuctdf41a4a; PRF=t%3DMCHP; A1S=d=AQABBIuI-mYCENM75g-1RxvRLBiYYn3r6mUFEgABCAEdLmdeZ-Ijb2UB9qMAAAcIi4j6Zn3r6mU&S=AQAAAhOXP8-W4p7gMIATG0tx63s; cmp=t=1732102191&j=1&u=1---&v=53; EuConsent=CQHuB4AQHuB4AAOACBENBQFoAP_gAEPgACiQKZNB9G7WTXFneXp2YPskOYUX0VBJ4MAwBgCBAcABzBIUIBwGVmAzJEyIICACGAIAIGBBIABtGAhAQEAAYIAFAABIAEgAIBAAIGAAACAAAABACAAAAAAAAAAQgEAXMBQgmAZEBFoIQUhAggAgAQAAAAAEAIgBCgQAEAAAQAAICAAIACgAAgAAAAAAAAAEAFAIEQAAAAECAotkfQAAAAAAAAAAAAAAAAABBTIAEg1KiAIsCQkIBAwggQAiCgIAKBAAAAAQIAAACYIChAGASowEQAgBAAAAAAAAAAQAIAAAIAEIAAgACBAAAAABAAEABAIAAAQAAAAAAAAAAAAAAAAAAAAAAAAAxACEEAAIAIIACCgAAAAEAAAAAAAAABEAAQAAAAAAAAAAAAABEAAAAAAAAAAAAAAAAAABAAAAAAAAAEAIgsAAAAAAAAAAAAAAAAAAIAA; axids=gam=y-D6u6S6xE2uK_Pd67HRy4OefGieRfEKiB~A&dv360=eS11cGZON0pKRTJ1RkwyRzhvLkFseTkzWDRVSFBsUTNtaX5B&ydsp=y-8BmzyhtE2uKeLoVJQo5VsAZuEn0lxCWq~A&tbla=y-br54pG1E2uKNCK2YMneD1EuBaVtqWq8h~A',\n",
        "'origin': 'https://finance.yahoo.com',\n",
        "'priority': 'u=1, i',\n",
        "'referer': 'https://finance.yahoo.com/markets/stocks/most-active/?start=0&count=100',\n",
        "'sec-ch-ua': '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
        "'sec-ch-ua-mobile': '?0',\n",
        "'sec-ch-ua-platform': '\"Windows\"',\n",
        "'sec-fetch-dest': 'empty',\n",
        "'sec-fetch-mode': 'cors',\n",
        "'sec-fetch-site': 'same-site',\n",
        "'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
        "'version': '0'}\n",
        "        r= requests.get(url,headers=headers,data=data)\n",
        "        j=json.loads(r.content)\n",
        "        self.data=pd.json_normalize(j['finance']['result'][0]['quotes'])\n",
        "        if int(self.data.shape[0]):\n",
        "         \n",
        "          self.dataframe_form()\n",
        "          self.transform_MarketCap()\n",
        "          self.transform_Volume()\n",
        "          self.data['Market_category']=self.data['marketCap.raw'].apply(self.market_category)\n",
        "          self.data['Current_position']=(self.data['regularMarketPrice.raw']-self.data['regularMarketOpen.raw']).apply(self.market_trend)\n",
        "          self.normalize_pp()\n",
        "          self.round_data()\n",
        "          self.load_data()\n",
        "          start+=100\n",
        "          i=int(self.data.shape[0])\n",
        "          print(f\"{i} is being processed\")\n",
        "          if i <100:\n",
        "            return(\"ETL process successfully completed.\")\n",
        "            break;\n",
        "\n",
        "        else:\n",
        "          return(\"No data found or Extraction is complete.\")\n",
        "```\n",
        "\n",
        "**Step 5: Data transformation:**\n",
        "\n",
        "Performing basic transformation to convert data into understandable format.\n",
        "1. **MarketCap.raw in Billions**:\n",
        "The **market cap.raw** values are divided by 1 billion to convert them into \"billions\".\n",
        "2. **Volume in millions**:\n",
        "The **regularMarketVolume.raw** is divided by 1 million to convert it into \"millions\".\n",
        "3. **current price normalization**:\n",
        "The formula (current price - 52-week low) / (52-week high - 52-week low) normalizes stock prices to a range of 0 to 1. It will indicate the position of the current price within the 52-week range.\n",
        "4. **current Market Trend**:\n",
        "Based on the difference between the opening and closing price of the stock, the market trend is classified as positive, negative, or sideways.\n",
        "5. **Company market category**:\n",
        "Stocks are categorized as small-cap, medium-cap, large-cap, or mega-cap based on their market cap value.\n",
        "\n",
        "```\n",
        " def dataframe_form(self):\n",
        "\n",
        "        self.data = pd.DataFrame(self.data)\n",
        "\n",
        "    def transform_MarketCap(self): # in billion\n",
        "      self.data['marketCap.raw']=round(self.data['marketCap.raw']/1000000000,2)\n",
        "\n",
        "    def transform_Volume(self): #in million\n",
        "      self.data['regularMarketVolume.raw']=round(self.data['regularMarketVolume.raw']/1000000,2)\n",
        "\n",
        "    def market_category(self,value):\n",
        "      if value<=2.0:\n",
        "        return \"Small cap\"\n",
        "      elif value>2.0 and value <=10.0:\n",
        "        return \"Medium cap\"\n",
        "      elif value >10.0 and value <=200.0:\n",
        "        return \"Large Cap\"\n",
        "      else:\n",
        "        return \"Mega Cap\"\n",
        "\n",
        "    def market_trend(self,value):\n",
        "      if value<0:\n",
        "        return \"Negative\"\n",
        "      elif value>0:\n",
        "        return \"Positive\"\n",
        "      else:\n",
        "        return \"Side-ways\"\n",
        "\n",
        "    def normalize_pp(self):\n",
        "      self.data[\"Normalize_price_posn\"]=round((self.data[\"regularMarketPrice.raw\"]-self.data[\"fiftyTwoWeekLow.raw\"])/(self.data[\"fiftyTwoWeekHigh.raw\"]-self.data[\"fiftyTwoWeekLow.raw\"]),2)\n",
        "\n",
        "    def round_data(self):\n",
        "      self.data[\"regularMarketChange.raw\"]=round(self.data[\"regularMarketChange.raw\"],2)\n",
        "      self.data[\"regularMarketChangePercent.raw\"]=round(self.data[\"regularMarketChangePercent.raw\"],2)\n",
        "```\n",
        "**Step 6: Data loading into Database:**\n",
        "\n",
        "Considering the most important column for loading the data into the MongoDB database, in this step, the data frame is converted into Python dictionaries, where each dictionary represents a row in the data frame. Using the \"**insert_many()**\" function uploading all fetched data at once.\n",
        "\n",
        "```\n",
        "def load_data(self):\n",
        "      data_main= self.data[['symbol','shortName','Market_category','Current_position','Normalize_price_posn','regularMarketPreviousClose.raw','regularMarketOpen.raw','regularMarketPrice.raw','marketCap.raw','regularMarketVolume.raw','regularMarketChange.raw','regularMarketChangePercent.raw','regularMarketDayLow.raw','regularMarketDayHigh.raw','fiftyTwoWeekLow.raw','fiftyTwoWeekHigh.raw']]\n",
        "      print(data_main.head())\n",
        "      Most_Active=data_main.to_dict(orient='records')\n",
        "      self.collection.insert_many(Most_Active)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2xVbntU0BjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges and Solution\n",
        "1. Handling large datasets: Data fetched in chunks of 100 records per request.\n",
        "2. Parsing data in the JSON\n",
        "2. MongoDB conectivity:Use of public IP address.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cSW7QkzRBEQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result\n",
        "1. Successfully executed the ETL pipeline for stock market data.\n",
        "2. Data stored in MongoDB is structured and normalized, enabling easy retrieval for further analysis or visualization.\n",
        "3. The system is scalable and reliable of handling real-time data updates."
      ],
      "metadata": {
        "id": "HAakkrSG9mzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "This project demonstrates the effective integration of API data retrieval, data processing, and database management to streamline stock market data handling. It offers a robust foundation for advanced financial data analysis and visualization tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "OT6Ob7IU935z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "Youtube: https://www.youtube.com/watch?v=084rmLU1UgA&t=368s\n",
        "\n",
        "Site: https://www.investopedia.com/insights/understanding-small-and-big-cap-stocks/\n",
        "\n",
        "Site: https://www.investopedia.com/terms/1/52-week-range.asp\n"
      ],
      "metadata": {
        "id": "PF-gpwaJ99PK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "QZFxM9nVMvfH",
        "1NGAP_eShKn7",
        "bEupVcxv8Lh5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}